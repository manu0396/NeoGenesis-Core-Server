name: Performance HIL Validation

on:
  workflow_call:
    inputs:
      base_url:
        description: "Server base URL"
        required: true
        type: string
      metrics_threshold_p95_ms:
        description: "Fail if p95 exceeds this threshold (ms)"
        required: false
        default: "50"
        type: string
      metrics_threshold_p99_ms:
        description: "Fail if p99 exceeds this threshold (ms)"
        required: false
        default: "75"
        type: string
  workflow_dispatch:
    inputs:
      base_url:
        description: "Server base URL"
        required: true
        default: "http://localhost:8080"
      metrics_threshold_p95_ms:
        description: "Fail if p95 exceeds this threshold (ms)"
        required: true
        default: "50"
      metrics_threshold_p99_ms:
        description: "Fail if p99 exceeds this threshold (ms)"
        required: true
        default: "75"

jobs:
  k6-latency-check:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup k6
        uses: grafana/setup-k6-action@v1

      - name: Run k6 latency benchmark
        id: k6
        env:
          BASE_URL: ${{ inputs.base_url }}
          JWT: ${{ secrets.NEOGENESIS_PERF_JWT }}
          K6_THRESHOLD_P95_MS: ${{ inputs.metrics_threshold_p95_ms }}
          K6_THRESHOLD_P99_MS: ${{ inputs.metrics_threshold_p99_ms }}
        run: |
          set -euo pipefail
          k6 run --summary-export k6-summary.json perf/k6/telemetry-latency.js

      - name: Evaluate p95/p99 and build evidence summary
        id: evaluate
        run: |
          set -euo pipefail
          P95_MS="$(jq -r '.metrics.http_req_duration.values["p(95)"] // .metrics.http_req_duration.values.p95 // empty' k6-summary.json)"
          P99_MS="$(jq -r '.metrics.http_req_duration.values["p(99)"] // .metrics.http_req_duration.values.p99 // empty' k6-summary.json)"

          if [ -z "$P95_MS" ] || [ -z "$P99_MS" ]; then
            echo "Unable to parse p95/p99 from k6-summary.json"
            exit 1
          fi

          echo "p95_ms=$P95_MS" >> "$GITHUB_OUTPUT"
          echo "p99_ms=$P99_MS" >> "$GITHUB_OUTPUT"

          THRESHOLD_P95="${{ inputs.metrics_threshold_p95_ms }}"
          THRESHOLD_P99="${{ inputs.metrics_threshold_p99_ms }}"
          PASS_P95="$(awk "BEGIN {print ($P95_MS <= $THRESHOLD_P95) ? \"true\" : \"false\"}")"
          PASS_P99="$(awk "BEGIN {print ($P99_MS <= $THRESHOLD_P99) ? \"true\" : \"false\"}")"

          {
            echo "# Performance HIL Summary"
            echo ""
            echo "- Base URL: \`${{ inputs.base_url }}\`"
            echo "- p95 latency (ms): \`${P95_MS}\` (threshold \`${THRESHOLD_P95}\`, pass=\`${PASS_P95}\`)"
            echo "- p99 latency (ms): \`${P99_MS}\` (threshold \`${THRESHOLD_P99}\`, pass=\`${PASS_P99}\`)"
            echo "- Run URL: \`${GITHUB_SERVER_URL}/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}\`"
          } | tee k6-summary.md

          if [ "$PASS_P95" != "true" ] || [ "$PASS_P99" != "true" ]; then
            echo "Latency SLO gate failed"
            exit 1
          fi

      - name: Upload performance evidence
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: k6-latency-evidence
          path: |
            k6-summary.json
            k6-summary.md
